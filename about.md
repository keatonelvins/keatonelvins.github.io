---
layout: about
title: about me
---

Hi! I'm a Master's student at NYU's Courant Institute of Mathematical Sciences focused on language model alignment and emergent behaviors. Here are some problem spaces I'm interested in:

* Human-AI collaboration: What happens when models learn from human feedback? How can we validate that systems are able to infer the user's intent?
* Generalization: Can models tell when they are working out-of-domain? How is their uncertainty expressed? And what is the importance of training data here?
* Reasoning: What factors play a role in eliciting reasoning abilities in LLM's? Is this reasoning "real"? How can we gain concrete insight on their internal processes?
  
I'm a big believer in learning through teaching. Poke around on here for my thoughts on some interesting papers, notes for whatever I'm working on, or anything else that came to mind.

In my free time, I love to read and [take photos](https://www.keat.one). I'm also very interested in music and plan to do more side projects as part of the Spotify developer community. Feel free to reach out if you want to chat!
